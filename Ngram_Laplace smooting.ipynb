{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新华社新闻语料地址\n",
    "corpus_path = '../article_9k.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取语料\n",
    "FILE = open(corpus_path).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unigram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(w_1,w_2...w_i) = \\prod_{i=1}^n \\frac{C(w_i)+1}{C(w)+|V|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### |V| 语料中 unigram 的种类数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = jieba.lcut(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts = len(set(TOKENS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigram_count(word):\n",
    "    if word in token_counts:\n",
    "        word_count = token_counts[word]\n",
    "    else:\n",
    "        word_count = 0\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_model(string):\n",
    "    str_list = jieba.lcut(string)\n",
    "    output = 0\n",
    "    for w in str_list:\n",
    "        w_count = get_unigram_count(w)\n",
    "        pw = (w_count + 1) / (len(TOKENS) + unigram_counts)\n",
    "        \n",
    "        # 因为pw是小于1的数，当连乘较多时，数值会非常小，甚至超出电脑所能表示的浮点数的精度，所以进行log处理，将连乘转变为和的形式\n",
    "        output += np.log10(pw)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19.035334517357814"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str A\n",
    "unigram_model('白石麻衣天下第一')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.60952943132795"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str B\n",
    "unigram_model('白麻衣石天第一下')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-26.437986041505344"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str A\n",
    "unigram_model('我一定要成为自然语言处理大师')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28.179289708939375"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str B\n",
    "unigram_model('我一样要吃饭自然语言处理大师')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比发现str A 的值较高而且实际中也是str A 更加符合正常语法规则更加通顺一点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Pr(sentence)  = Pr( w_1 \\cdot w_2 \\cdots w_n) = \\prod \\frac{count(w_i,w_{i+1})+1} {count(w_i)+|V|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_TOKENS = [TOKENS[i] + TOKENS[i+1] for i in range(len(TOKENS)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_token_counts = Counter(bigram_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = len(set(bigram_TOKENS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_count(word):\n",
    "    if word in bigram_token_counts:\n",
    "        word_count = bigram_token_counts[word]\n",
    "    else:\n",
    "        word_count = 0\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_model(string):\n",
    "    str_list = jieba.lcut(string)\n",
    "    output = 0\n",
    "    for i in range(len(str_list)-1):\n",
    "        w = str_list[i]\n",
    "        w_next = str_list[i+1]\n",
    "        two_gram_w = w + w_next\n",
    "        two_gram_pw = (get_bigram_count(two_gram_w) + 1) / (len(bigram_TOKENS) + bigram_counts)\n",
    "        one_gram_pw = (get_unigram_count(w)+1) / (len(TOKENS) + unigram_counts)\n",
    "        \n",
    "        pro = two_gram_pw / one_gram_pw\n",
    "        \n",
    "        output += np.log10(pro)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.897996308578186"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model('谁会买小米手机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.897996308578186"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model('谁会买小米汽车')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.237589486313484"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model('python是世界上最好的语言')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.527624097676002"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model('python是世界上最好的跑车')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
